{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6a9262"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lukebarousse/Python_Data_Analytics_Course/blob/main/1_Basics/19_Exercise_Python_Library.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-tcjfaPxSd3"
      },
      "source": [
        "# Exercise - Python Library - Data Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWsMxXOSxSd4"
      },
      "source": [
        "##### Problem Statement\n",
        "\n",
        "Given a list of dictionaries, each representing a different role, where each dictionary contains a key `'job_skills'` with a string value representing a list of skills, and a `'job_date' represented also in a string value.\n",
        "- Turn the `'job_date'` from a string value to a date time object.\n",
        "- Turn the `'job_skills'` from a string value to an actual list object.\n",
        "\n",
        "\n",
        "First we'll create a list called `data_science_jobs`, containing dictionaries. Each dictionary represents a data science job role:  \n",
        "- `'job_title'`: The title of the job  \n",
        "- `'job_skills'`: A string that represents a list of skills required  \n",
        "- `'job_date'` : A string that represents a date  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBzqQXNpxSd4"
      },
      "outputs": [],
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wos8wpawxSd6"
      },
      "source": [
        "If we print this variable we can see that the `'job_skills'` and `'job_date'` values are a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1uUJ8bAxSd6",
        "outputId": "a6048bc1-d0fb-49cd-d9e0-e6ab4e0462e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'}\n"
          ]
        }
      ],
      "source": [
        "print(data_science_jobs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOfPehR3xSd8"
      },
      "source": [
        "### `datetime` Conversion (`job_date`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiwXuktDxSd8"
      },
      "source": [
        "First let's import datetime in and test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFe4R65TxSd9",
        "outputId": "4571460a-9c3c-4614-c943-04cab903d068"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datetime.datetime(2024, 5, 3, 17, 54, 59, 289836)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# show current date and time\n",
        "datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4sAYssExSeB"
      },
      "source": [
        "Let's test one value from our `job_date` key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hbs3B0oxSeC",
        "outputId": "173110ad-70c8-419e-c474-ddc4fe7c062f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-12\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "test_date = data_science_jobs[0]['job_date']\n",
        "\n",
        "print(test_date)\n",
        "print(type(test_date))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ukEdt-RxSeC"
      },
      "source": [
        "We'll now use the `.strptime()` method to convert it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-XusszVxSeD",
        "outputId": "10586503-3b8b-43fd-9824-d6f055e7107a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-12 00:00:00\n"
          ]
        }
      ],
      "source": [
        "print(datetime.strptime(test_date, '%Y-%m-%d'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfU4JykNxSeD"
      },
      "source": [
        "It works! Let's convert all them in the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gkx_nxvtxSeE",
        "outputId": "af3ccd1d-f88a-4c9c-ad7b-560390872101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': \"['Python', 'SQL', 'Machine Learning']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 12, 0, 0)},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 15, 0, 0)},\n",
              " {'job_title': 'Data Analyst',\n",
              "  'job_skills': \"['SQL', 'R', 'Tableau']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 10, 0, 0)},\n",
              " {'job_title': 'Business Intelligence Developer',\n",
              "  'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 8, 0, 0)},\n",
              " {'job_title': 'Data Engineer',\n",
              "  'job_skills': \"['Python', 'Spark', 'Hadoop']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 18, 0, 0)},\n",
              " {'job_title': 'AI Specialist',\n",
              "  'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 20, 0, 0)}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]\n",
        "from datetime import datetime\n",
        "\n",
        "for job in data_science_jobs:\n",
        "  job['job_date'] = datetime.strptime(job['job_date'], '%Y-%m-%d')\n",
        "\n",
        "data_science_jobs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KV_fUA5xSeE"
      },
      "source": [
        "### `ast` Conversion (`job_skills`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLqyosIUxSeE"
      },
      "source": [
        "Now let's convert the skills to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXdjmXsDxSeE",
        "outputId": "bda7200f-56b5-477a-884a-85738a32859b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Python', 'SQL', 'Machine Learning']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_skills = data_science_jobs[0]['job_skills']\n",
        "\n",
        "print(test_skills)\n",
        "type(test_skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCH_3nNExSeE",
        "outputId": "f17df68c-b0ea-46e3-8d85-60be7317fef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Python', 'SQL', 'Machine Learning']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ast\n",
        "\n",
        "print(ast.literal_eval(test_skills))\n",
        "type(ast.literal_eval(test_skills))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI1Aa0PsxSeF"
      },
      "source": [
        "Nice let's do it for all now! (while doing the datetime)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4poQ5y01xSeF",
        "outputId": "5a79d8ca-87e3-4e11-fe72-dedc20263360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': ['Python', 'SQL', 'Machine Learning'],\n",
              "  'job_date': datetime.datetime(2023, 5, 12, 0, 0)},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': ['Python', 'TensorFlow', 'Deep Learning'],\n",
              "  'job_date': datetime.datetime(2023, 5, 15, 0, 0)},\n",
              " {'job_title': 'Data Analyst',\n",
              "  'job_skills': ['SQL', 'R', 'Tableau'],\n",
              "  'job_date': datetime.datetime(2023, 5, 10, 0, 0)},\n",
              " {'job_title': 'Business Intelligence Developer',\n",
              "  'job_skills': ['SQL', 'PowerBI', 'Data Warehousing'],\n",
              "  'job_date': datetime.datetime(2023, 5, 8, 0, 0)},\n",
              " {'job_title': 'Data Engineer',\n",
              "  'job_skills': ['Python', 'Spark', 'Hadoop'],\n",
              "  'job_date': datetime.datetime(2023, 5, 18, 0, 0)},\n",
              " {'job_title': 'AI Specialist',\n",
              "  'job_skills': ['Python', 'PyTorch', 'AI Ethics'],\n",
              "  'job_date': datetime.datetime(2023, 5, 20, 0, 0)}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]\n",
        "\n",
        "import ast\n",
        "from datetime import datetime\n",
        "\n",
        "for job in data_science_jobs:\n",
        "    job['job_date'] = datetime.strptime(job['job_date'], '%Y-%m-%d')\n",
        "    job['job_skills'] = ast.literal_eval(job['job_skills'])\n",
        "\n",
        "data_science_jobs"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}